{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1796e1-7891-488e-bd23-0de9faac97db",
   "metadata": {},
   "source": [
    "*Disclaimer: Currently, this notebook fetches resources from Internet Archive's Wayback Machine. In a future where larger amounts of the National Library of Norway's Web Archive are accessible, we hope to enable similar functionality for our own collection.*\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c85d6-8323-42f8-8ccd-dcd4c4bfc88e",
   "metadata": {},
   "source": [
    "# Objective of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa44ae1-8d3f-40f3-a512-b8717dd5af15",
   "metadata": {},
   "source": [
    "The objective of this notebook is to obtain archived versions of webpages from the Internet Archive (IA), and then analyse changes in their layout over time. This can be helpful for a range over problems and disciplines, including media and communication studies, computer science and not least media history.\n",
    "\n",
    "This notebook uses the case of front pages from the Norwegian Broadcasting Company (NRK), which has been archived by IA since 1996 and up until today. We will fetch and capture the archived versions of `nrk.no`, but it is very easy to change that to another domain, such as `bbc.co.uk`. The script is tailored to fetch and capture with ~90 days intervals, but that can also be adjusted easily.\n",
    "\n",
    "The notebook is structured into several steps:\n",
    "1. Fetching URLs of different versions of a page\n",
    "2. Capture screenshots\n",
    "3. Compare screenshot similarity (SSIM)\n",
    "4. Visualise changes in SSIM score over time\n",
    "\n",
    "## Installing necessery packages\n",
    "You need to install various packages before running this notebook.\n",
    "\n",
    "If you are comfortable with terminal/CLI, you can activate your desired python/conda environment and run `pip install waybackpy selenium opencv-python scikit-image plotly`.\n",
    "\n",
    "An alternative is to install the packages from this notebook. Remove `# ` in the start of each line in the cell below, and then run the cell with **⇧** + **↵ Enter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d17337-0e19-4798-a254-396ae36ccda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install waybackpy\n",
    "# !pip install selenium\n",
    "# !pip install opencv-python\n",
    "# !pip install scikit-image\n",
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e40a93-4086-4f77-bf9c-32e0cf79535d",
   "metadata": {},
   "source": [
    "# 1. Fetch IAWB URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ffef2-9dc5-4cb7-b344-a9f3a6e43641",
   "metadata": {},
   "source": [
    "First, we need to fetch the URLs of different versions that can be replayed in IA's Wayback Machine. To do this, we make use of the `waybackpy` package that utilises IA's CDX Server API.\n",
    "\n",
    "The code cell below contains a function to fetch URLs for archived versions between 1996 and 2024 with a 90 days interval. To change the interval, simply change the value If you want another page than `http://www.nrk.no/`, simply change that value into e.g. of `http://bbc.co.uk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2e862-d813-4340-a02e-b2d4ca02255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from waybackpy import WaybackMachineCDXServerAPI\n",
    "from datetime import datetime\n",
    "\n",
    "def get_quarterly_archived_urls(domain, start_year=1996, end_year=2024):\n",
    "    \"\"\"Fetch one archived snapshot every 3 months from Wayback Machine.\"\"\"\n",
    "    cdx = WaybackMachineCDXServerAPI(domain)\n",
    "    all_snapshots = list(cdx.snapshots())\n",
    "    \n",
    "    quarterly_urls = []\n",
    "    last_date = None\n",
    "\n",
    "    for snapshot in all_snapshots:\n",
    "        snapshot_date = datetime.strptime(snapshot.timestamp, \"%Y%m%d%H%M%S\")\n",
    "        \n",
    "        # One snapshot per quarter\n",
    "        if last_date is None or (snapshot_date - last_date).days >= 90: # \"90\" defines the number of days between each version\n",
    "            quarterly_urls.append(snapshot.archive_url)\n",
    "            last_date = snapshot_date\n",
    "\n",
    "    return quarterly_urls\n",
    "\n",
    "urls = get_quarterly_archived_urls(\"http://www.nrk.no/\")\n",
    "print(f\"Retrieved {len(urls)} URLs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d8e158-e6cd-492b-b0e7-f1997b1eae80",
   "metadata": {},
   "source": [
    "For documentation, the fetched URLs can also be stored in a JSONL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea95f04-d43a-409e-a641-4e41ec5fb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export URLs to JSONL\n",
    "import json\n",
    "with open(\"./export/urls_from_IAWB.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in urls:\n",
    "        json.dump({\"url\": item}, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Exported to urls_from_IAWB.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b84fea-be10-4d2d-9d52-1454382d54e8",
   "metadata": {},
   "source": [
    "# 2. Capture screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c92db-1dd5-4370-858c-2b1846159a62",
   "metadata": {},
   "source": [
    "All URLs are now stored in a list with the variable name `urls`. For each of these URLs, we want to create screenshots. This can be done automatically, using what is called a [headless browser](https://en.wikipedia.org/wiki/Headless_browser).\n",
    "\n",
    "The cell below make use of Selenium Webdriver and a headless version of Chrome, and visits each of the archived versions we fetched earlier, producing a screenshot of how the archived version is rendered in IA's Wayback Machine.\n",
    "\n",
    "***NOTICE:*** *For the case of* ***`nrk.no`***, *you should expect 104 images to be created in the* ***`screenshots`*** *folder. This will take quite some time (~60 min), as the code only uses instance of the headless browser. If you want to reduce the runtime, it is possible to setup up several instances, but you can also reduce the chronological scope (1996-2024), or increase the interval (90 days).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d965e01-4cb7-47ce-aca8-e3c62cc73d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "def capture_screenshots(urls):\n",
    "    \"\"\"Captures screenshots for a list of archived URLs.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(3)  # Allow some time for page elements to load\n",
    "            screenshot_path = f\"screenshots/snapshot_{i}.png\"\n",
    "            driver.save_screenshot(screenshot_path)\n",
    "            print(f\"Saved: {screenshot_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to capture {url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# Capture screenshots\n",
    "capture_screenshots(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839af0d7-afe0-46b8-9d89-1160f30e48ac",
   "metadata": {},
   "source": [
    "# 3. Compare screenshot similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6e59a-4deb-493a-a238-747b0aa4f081",
   "metadata": {},
   "source": [
    "After all screenshot images have been created, it is time to analyse their similarity.\n",
    "\n",
    "This script uses a simple approach, using `opencv` to identify visual edges in the screenshots and calculate a [Structural Similarity Index Measure (SSIM) score](https://en.wikipedia.org/wiki/Structural_similarity_index_measure) for each pair of images. Each image is compared to the next, so that a screenshot from Dec 1996 will be compared to a screenshot from March 1997.\n",
    "\n",
    "SSIM scores ranges from -1 to +1. -1 indicates no similarity at all (one complete white and one complete black image), while +1 indicates that the images are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e3b3b-ef38-4bfe-a0c4-f322f5705c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import os\n",
    "import re\n",
    "\n",
    "def compare_all_screenshots(directory=\"screenshots/\"):\n",
    "    \"\"\"Compare all screenshots sequentially to detect major layout shifts.\"\"\"\n",
    "\n",
    "    # Get all valid snapshot files matching \"snapshot_X.png\"\n",
    "    files = [f for f in os.listdir(directory) if re.match(r\"snapshot_\\d+\\.png\", f)]\n",
    "    \n",
    "    # Sort numerically by extracting the snapshot number\n",
    "    files = sorted(files, key=lambda x: int(re.search(r\"snapshot_(\\d+).png\", x).group(1)))\n",
    "\n",
    "    ssim_scores = []\n",
    "\n",
    "    for i in range(len(files) - 1):\n",
    "        img1_path = os.path.join(directory, files[i])\n",
    "        img2_path = os.path.join(directory, files[i + 1])\n",
    "\n",
    "        img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize to match dimensions\n",
    "        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "\n",
    "        # Compute SSIM\n",
    "        score, diff = ssim(img1, img2, full=True)\n",
    "        diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "        ssim_scores.append(score)\n",
    "        print(f\"SSIM between {files[i]} and {files[i+1]}: {score:.4f}\")\n",
    "\n",
    "        # Ensure the \"diff\" directory exists\n",
    "        os.makedirs(\"diff\", exist_ok=True)\n",
    "\n",
    "        # Save difference images for visualization\n",
    "        cv2.imwrite(f\"diff/diff_{i}.png\", diff)\n",
    "\n",
    "    return ssim_scores\n",
    "\n",
    "# Example usage\n",
    "ssim_scores = compare_all_screenshots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6466517-06cc-42c5-9b83-36025a85bd59",
   "metadata": {},
   "source": [
    "# 4. Visualise SSIM scores over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a310ea-1b3b-42c2-ac57-bad9d26c842c",
   "metadata": {},
   "source": [
    "When we have assigned SSIM scores to each pair of images, we can visualise the similarity of screenshots over time. High SSIM scores indicates a high similarity between one version and the next, while low SSIM scores indicates more significant changes.\n",
    "\n",
    "Using `plotly`, we can make an interactive line plot graph that shows development over time.\n",
    "This can be be hovered over and exported as a png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed41f1a-ffb5-4691-8e95-0fe027a512b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_ssim_timeline_interactive(ssim_scores, urls):\n",
    "    \"\"\"Plot interactive SSIM scores against archive timestamps using Plotly.\"\"\"\n",
    "    timestamps = [extract_timestamp(url) for url in urls]\n",
    "\n",
    "    # Adjust the timestamps list to match SSIM score count\n",
    "    timestamps = timestamps[1:len(ssim_scores)+1]  # Keep only valid timestamps\n",
    "\n",
    "    # Create interactive Plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add SSIM scores as a line plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=timestamps,\n",
    "        y=ssim_scores,\n",
    "        mode='lines+markers',\n",
    "        marker=dict(size=6, color='blue'),\n",
    "        line=dict(width=2),\n",
    "        name=\"SSIM Score\"\n",
    "    ))\n",
    "\n",
    "    # Add a threshold line at SSIM = 0.55\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=timestamps,\n",
    "        y=[0.55] * len(ssim_scores),\n",
    "        mode='lines',\n",
    "        line=dict(color='red', dash='dash'),\n",
    "        name=\"Breakage Threshold (0.55)\"\n",
    "    ))\n",
    "\n",
    "    # Layout customization\n",
    "    fig.update_layout(\n",
    "        title=\"Interactive Web Layout Change Over Time (NRK.no)\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"SSIM Similarity Score\",\n",
    "        xaxis=dict(tickangle=45),\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Example usage\n",
    "plot_ssim_timeline_interactive(ssim_scores, urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166691c-77f3-435f-8881-057a1549a542",
   "metadata": {},
   "source": [
    "# 5. Assemble all screenshot in a montage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1fa26-7547-40f0-bf01-0ab804c7d54a",
   "metadata": {},
   "source": [
    "When we have all these images, we can also produce a montage.\n",
    "\n",
    "Running the cell below will produce a `montage.png` in the export folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a94a6e-d9b3-4d3c-9816-c07e765b695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- CONFIGURATIONS ----\n",
    "input_folder = \"screenshots\"  # Change this to your folder path\n",
    "output_file = \"export/montage.png\"\n",
    "\n",
    "# ---- MONTAGE SETTINGS ----\n",
    "num_images = 103\n",
    "img_width, img_height = 1200, 992  # Your image size\n",
    "columns = 10  # Number of columns in the grid\n",
    "rows = math.ceil(num_images / columns)  # Number of rows needed\n",
    "resize_width, resize_height = 192, 180  # Resize each image to fit 1920x1080\n",
    "\n",
    "# ---- LOAD IMAGES ----\n",
    "image_files = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(('png', 'jpg', 'jpeg'))])\n",
    "image_files = image_files[:num_images]  # Limit to 104 images\n",
    "\n",
    "# Check if we have enough images\n",
    "assert len(image_files) == num_images, f\"Expected {num_images} images, but found {len(image_files)}\"\n",
    "\n",
    "# ---- CREATE A BLANK CANVAS ----\n",
    "montage_width = columns * resize_width\n",
    "montage_height = rows * resize_height\n",
    "montage = Image.new('RGB', (montage_width, montage_height), (255, 255, 255))\n",
    "\n",
    "# ---- PROCESS AND PLACE IMAGES ----\n",
    "for index, img_path in enumerate(image_files):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((resize_width, resize_height))  # Resize image\n",
    "\n",
    "    # Compute position in the grid\n",
    "    x_offset = (index % columns) * resize_width\n",
    "    y_offset = (index // columns) * resize_height\n",
    "\n",
    "    # Paste onto the montage canvas\n",
    "    montage.paste(img, (x_offset, y_offset))\n",
    "\n",
    "# ---- SAVE AND DISPLAY ----\n",
    "montage.save(output_file)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(montage)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Montage saved as {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
